{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d40b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc501f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'recipe1M_layers/layer1.json'\n",
    "MODEL_CKPT = '/common/home/dm1487/loaded_models/bert-base-uncased'\n",
    "os.listdir(MODEL_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the WordPiece Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
    "# loading Bert and adding it to the GPU.\n",
    "model = AutoModel.from_pretrained(MODEL_CKPT, output_hidden_states=True).to('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8857a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Code to tokenize the dataset parallel for each type - title, ingredients, instructions, full\n",
    "def tokenize(id_, col):\n",
    "    return tokenizer(col, padding='max_length', max_length=512, truncation=True)\n",
    "\n",
    "dataset_encoded = None\n",
    "data_df = None\n",
    "layer = 'dataset_tokenized_instructions.pkl'\n",
    "layer_csv = 'layer3_preprocessed.csv'\n",
    "\n",
    "if os.path.exists(layer) :\n",
    "    with open(layer, 'rb') as f:\n",
    "        dataset_encoded = pickle.load(f)\n",
    "else:    \n",
    "    if os.path.exists(layer_csv):\n",
    "        print('here')\n",
    "        data_df = pd.read_csv(layer_csv)\n",
    "        print('done')\n",
    "    else:\n",
    "        data_dict = []\n",
    "        data = None\n",
    "        with open(DATA_FILE, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for i in tqdm(data):\n",
    "            ingredients = ' '.join([ingred['text'] for ingred in i['ingredients']])\n",
    "            instructions = ' '.join([f\"{instruct['text']}\" for idx, instruct in enumerate(i['instructions'])])\n",
    "            title = i['title']\n",
    "            id_ = i['id']\n",
    "            data_dict.append({\n",
    "                \"id\": id_,\n",
    "                \"title\": title,\n",
    "                \"ingredients\": ingredients,\n",
    "                \"instructions\": instructions,\n",
    "                \"full\": ' '.join([title, ingredients, instructions])\n",
    "            })\n",
    "        data_df = pd.DataFrame(data_dict)\n",
    "        data_df.to_csv(layer_csv, index=False)\n",
    "\n",
    "    dataset = Dataset.from_pandas(data_df)\n",
    "    dataset_encoded = dataset.map(tokenize, input_columns=['id', 'instructions'], batched=True, batch_size=1000, keep_in_memory=True)\n",
    "    with open(layer, 'wb') as f:\n",
    "        pickle.dump(dataset_encoded, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using multiple GPUs\n",
    "parallel_model = DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for fast data extraction\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': torch.tensor(self.dataset[idx]['input_ids']).long(), 'attention_mask': torch.tensor(self.dataset[idx]['attention_mask']).float()}\n",
    "\n",
    "dataset = TextDataset(dataset_encoded)\n",
    "dataloader = DataLoader(dataset, batch_size=220, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c51e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert embedding extraction\n",
    "features_folder =  'features_text_instructions'\n",
    "if not os.path.exists(features_folder):\n",
    "    os.mkdir(features_folder)\n",
    "features = torch.tensor([])\n",
    "layers = [-2]\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(dataloader)):\n",
    "        output =  parallel_model(**batch)\n",
    "        states = output[2][-2]\n",
    "        if features.shape[0] == 0:\n",
    "            features = torch.mean(states, dim=1)\n",
    "        else:\n",
    "            features = torch.vstack([features, torch.mean(states, dim=1)])\n",
    "            \n",
    "        if (idx % 500 == 0  and idx != 0) or (idx == len(dataset) - 1):\n",
    "            print('saving here at', idx)\n",
    "            torch.save(features.cpu(), os.path.join(features_folder, f'{idx}.pkl'))\n",
    "            features = torch.tensor([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa018618",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(features.cpu(), os.path.join(features_folder, f'{idx}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
