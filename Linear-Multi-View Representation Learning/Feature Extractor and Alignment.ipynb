{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2275df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining text features to one\n",
    "TEXT_FEATURES_PATH = 'features_text_instructions'\n",
    "features = torch.tensor([])\n",
    "for i in sorted(os.listdir(TEXT_FEATURES_PATH), key=lambda x: int(x.split('.')[0])):\n",
    "    if 'pkl' in i:\n",
    "        print(i)\n",
    "        load_file = torch.load(os.path.join(TEXT_FEATURES_PATH, i))\n",
    "        if features.size(0) == 0:\n",
    "            features = load_file\n",
    "        else:\n",
    "            features = torch.vstack([features, load_file])\n",
    "features = features.cpu()\n",
    "torch.save(features, 'instructions_text_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7692a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FEATURES_PATH = 'gen_data_val'\n",
    "features = torch.tensor([])\n",
    "for i in sorted(os.listdir(IMAGE_FEATURES_PATH)):\n",
    "    pre_pre_path = os.path.join(IMAGE_FEATURES_PATH, i)\n",
    "    print(pre_pre_path)\n",
    "    for j in sorted(os.listdir(pre_pre_path)):\n",
    "        pre_path = os.path.join(pre_pre_path, j)\n",
    "        print(pre_path)\n",
    "        all_files = sorted(os.listdir(pre_path))\n",
    "        image_features = sorted(all_files[:-1], key=lambda x: int(x))\n",
    "        paths = all_files[-1]\n",
    "        for k in image_features:\n",
    "            feature = torch.load(os.path.join(pre_path, k))\n",
    "            if features.size(0) == 0:\n",
    "                features = feature\n",
    "            else:\n",
    "                features = torch.vstack([features, feature])\n",
    "    print(features.size())\n",
    "torch.save(features.cpu(), 'full_image_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da994a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_LAYERS = 'recipe1M_layers/layer2.json'\n",
    "f = open(TEXT_LAYERS, 'rb')\n",
    "data_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map_list = []\n",
    "for i in data_map:\n",
    "    for j in i['images']:\n",
    "        data_map_list.append([i['id'], j['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map_df = pd.DataFrame(data_map_list, columns=['id', 'image_id'])\n",
    "data_map_df['id'] = data_map_df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29606b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map_df.reset_index(inplace=True)\n",
    "data_map_df.drop(columns=['index'], inplace=True)\n",
    "data_map_df = data_map_df.set_index('id')\n",
    "data_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_LAYERS_1 = 'recipe1M_layers/layer1.json'\n",
    "f = open(TEXT_LAYERS_1, 'rb')\n",
    "text_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_list = []\n",
    "for i in text_map:\n",
    "    text_data_list.append(i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda19658",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_map_df = pd.DataFrame(text_data_list, columns=['id'])\n",
    "text_map_df['id'] = text_map_df['id'].astype(str)\n",
    "text_map_df.reset_index(inplace=True)\n",
    "# text_map_df.drop(columns=['index'], inplace=True)\n",
    "text_map_df = text_map_df.set_index('id')\n",
    "text_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = text_map_df.join(data_map_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ccc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_images_map_df = test[test['image_id']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d2ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FEATURES_PATH = 'gen_data_train'\n",
    "image_paths = []\n",
    "for i in sorted(os.listdir(IMAGE_FEATURES_PATH)):\n",
    "    pre_pre_path = os.path.join(IMAGE_FEATURES_PATH, i)\n",
    "    for j in sorted(os.listdir(pre_pre_path)):\n",
    "        pre_path = os.path.join(pre_pre_path, j)\n",
    "        all_files = sorted(os.listdir(pre_path))\n",
    "        paths = all_files[-1]\n",
    "        f = open(os.path.join(pre_path, paths), 'r')\n",
    "        img_paths = f.readlines()\n",
    "        for k in img_paths:\n",
    "            image_paths.append([k.strip(),k.strip().split('/')[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_map_df = pd.DataFrame(image_paths, columns=['path', 'image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de321c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_map_df.reset_index(inplace=True)\n",
    "image_map_df = image_map_df.set_index('image_id')\n",
    "image_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ec097",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_images_map_df.reset_index(inplace=True)\n",
    "text_with_images_map_df = text_with_images_map_df.set_index('image_id')\n",
    "full_data_map = text_with_images_map_df.join(image_map_df, lsuffix='_text', rsuffix='_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53306794",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map = full_data_map.fillna(-1)\n",
    "train_map = train_map[train_map['index_image'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map.reset_index(inplace=True)\n",
    "train_map['index_image'] = train_map['index_image'].astype(int)\n",
    "train_map.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26257de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FEATURES_PATH = 'gen_data_train'\n",
    "counter = []\n",
    "for i in sorted(os.listdir(IMAGE_FEATURES_PATH)):\n",
    "    pre_pre_path = os.path.join(IMAGE_FEATURES_PATH, i)\n",
    "    for j in sorted(os.listdir(pre_pre_path)):\n",
    "        pre_path = os.path.join(pre_pre_path, j)\n",
    "        all_files = sorted(os.listdir(pre_path))\n",
    "        paths = all_files[-1]\n",
    "        f = open(os.path.join(pre_path, paths), 'r')\n",
    "        img_paths = f.readlines()\n",
    "        image_features = sorted(all_files[:-1], key=lambda x: int(x))\n",
    "        img_counter = 0\n",
    "        for k in image_features:\n",
    "            feature = torch.load(os.path.join(pre_path, k))\n",
    "            img_counter += feature.size(0)\n",
    "        if len(img_paths) != img_counter:\n",
    "            print('here', os.path.join(pre_path, paths))\n",
    "        counter.append((len(img_paths), img_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = torch.load('full_image_complete.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = torch.load('full_text_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_features = text_features[train_map['index_text']]\n",
    "train_img_features = img_features[train_map['index_image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_img_features, 'full_img_train.pkl')\n",
    "torch.save(train_text_features, 'full_text_best_train.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
