{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99eb5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/apc120/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "with open('/common/home/apc120/Downloads/labelled/embeddings_test1.pkl', 'rb') as f1:\n",
    "    test_emb = pickle.load(f1)\n",
    "test_img_all = test_emb[0]\n",
    "test_txt_all = test_emb[1]\n",
    "\n",
    "\n",
    "with open('/common/home/apc120/Downloads/labelled/instructions_embeddings_test.pkl', 'rb') as f2:\n",
    "    test_data_instr = pickle.load(f2)\n",
    "test_txt_instr = test_data_instr[0]\n",
    "\n",
    "\n",
    "with open('/common/home/apc120/Downloads/labelled/ingredients_embeddings_test.pkl', 'rb') as f3:\n",
    "    test_data_ingr = pickle.load(f3)\n",
    "test_txt_ingr = test_data_ingr[0]\n",
    "\n",
    "\n",
    "with open('/common/home/apc120/Downloads/labelled/title_embeddings_test.pkl', 'rb') as f4:\n",
    "    test_data_title = pickle.load(f4)\n",
    "test_txt_title = test_data_title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af28c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "def calculate_rank_recall(txt_data, img_data):\n",
    "    results_dict = {}\n",
    "    projection_txt, projection_img = txt_data, img_data\n",
    "    \n",
    "    idxs = range(1000)\n",
    "    \n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0,5:0.0,10:0.0}\n",
    "    \n",
    "    for i in range(10):\n",
    "        ids = random.sample(range(0,txt_data.shape[0]-1), 1000)\n",
    "        \n",
    "        txt_sample = projection_txt[ids,:]\n",
    "        img_sample = projection_img[ids,:]\n",
    "        \n",
    "        similarity = np.dot(txt_sample.cpu().numpy(), img_sample.T.cpu().numpy())\n",
    "\n",
    "        med_rank = []\n",
    "        \n",
    "        recall = {1:0.0,5:0.0,10:0.0}\n",
    "        \n",
    "        for ii in idxs:\n",
    "            # get a column of similarities\n",
    "            sim = similarity[ii,:]\n",
    "            # sort indices in descending order\n",
    "            sorting = np.argsort(sim)[::-1].tolist()\n",
    "            # find where the index of the pair sample ended up in the sorting\n",
    "            pos = sorting.index(ii)  \n",
    "            if (pos+1) == 1:\n",
    "                recall[1]+=1\n",
    "            if (pos+1) <=5:\n",
    "                recall[5]+=1\n",
    "            if (pos+1)<=10:\n",
    "                recall[10]+=1\n",
    "            # store the position\n",
    "            med_rank.append(pos+1)\n",
    "        for i in recall.keys():\n",
    "            recall[i]=recall[i]/1000\n",
    "        med = np.median(med_rank)\n",
    "        for i in recall.keys():\n",
    "            glob_recall[i]+=recall[i]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] = glob_recall[i]/10\n",
    "    med_dict = {}\n",
    "    med_dict[\"mean_median\"] = np.average(glob_rank)\n",
    "    med_dict[\"recall\"] = glob_recall\n",
    "    med_dict[\"median_all\"] = glob_rank\n",
    "    print(\"Result:\",med_dict)\n",
    "    return med_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e06ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self,output_size,input_size=1024):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.output = nn.Linear(512, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6a67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class ImgEncoder(nn.Module):\n",
    "    def __init__(self,output_size,input_size=1024):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.output = nn.Linear(512, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71839d9",
   "metadata": {},
   "source": [
    "<h1>All Text Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abef1efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'mean_median': 5.55, 'recall': {1: 0.2414, 5: 0.4939, 10: 0.603}, 'median_all': [6.0, 5.5, 6.0, 6.0, 5.0, 5.0, 6.0, 5.0, 6.0, 5.0]}\n"
     ]
    }
   ],
   "source": [
    "img_model=torch.load('64_mse_best_img_model.pth')\n",
    "txt_model = torch.load('64_mse_best_txt_model.pth')\n",
    "with torch.no_grad():\n",
    "    img_model.eval()\n",
    "    txt_model.eval()    \n",
    "    test_result = calculate_rank_recall(txt_model(torch.tensor(test_txt_all).to('cuda')),img_model(torch.tensor(test_img_all).to('cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a9e30d",
   "metadata": {},
   "source": [
    "<h1>Instructions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94f1bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'mean_median': 32.0, 'recall': {1: 0.0824, 5: 0.22209999999999996, 10: 0.31410000000000005}, 'median_all': [36.0, 31.5, 30.0, 29.0, 35.0, 29.0, 36.5, 29.0, 32.0, 32.0]}\n"
     ]
    }
   ],
   "source": [
    "img_model=torch.load('64instr_mse_best_img_model.pth')\n",
    "txt_model = torch.load('64instr_mse_best_txt_model.pth')\n",
    "with torch.no_grad():   \n",
    "    img_model.eval()\n",
    "    txt_model.eval()\n",
    "    test_result = calculate_rank_recall(txt_model(torch.tensor(test_txt_instr).to('cuda')),img_model(torch.tensor(test_img_all).to('cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2da15e",
   "metadata": {},
   "source": [
    "<h1>Ingredients</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b79f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'mean_median': 38.55, 'recall': {1: 0.0654, 5: 0.18980000000000002, 10: 0.2757}, 'median_all': [41.0, 37.5, 45.0, 34.0, 39.0, 38.0, 35.0, 38.0, 36.0, 42.0]}\n"
     ]
    }
   ],
   "source": [
    "img_model=torch.load('64ingr_mse_best_img_model.pth')\n",
    "txt_model = torch.load('64ingr_mse_best_txt_model.pth')\n",
    "with torch.no_grad():    \n",
    "    img_model.eval()\n",
    "    txt_model.eval()\n",
    "    test_result = calculate_rank_recall(txt_model(torch.tensor(test_txt_ingr).to('cuda')),img_model(torch.tensor(test_img_all).to('cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9bd11",
   "metadata": {},
   "source": [
    "<h1>Title</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5d3641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'mean_median': 111.7, 'recall': {1: 0.027200000000000002, 5: 0.09299999999999999, 10: 0.1507}, 'median_all': [117.0, 106.0, 126.0, 110.0, 127.0, 108.0, 122.0, 97.0, 96.5, 107.5]}\n"
     ]
    }
   ],
   "source": [
    "img_model=torch.load('64title_mse_best_img_model.pth')\n",
    "txt_model = torch.load('64title_mse_best_txt_model.pth')\n",
    "with torch.no_grad():\n",
    "    img_model.eval()\n",
    "    txt_model.eval()\n",
    "    test_result = calculate_rank_recall(txt_model(torch.tensor(test_txt_title).to('cuda')),img_model(torch.tensor(test_img_all).to('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea494b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
